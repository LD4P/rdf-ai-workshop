{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction and Setup for Sinopia's Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%reload_ext lab_black\n",
    "\n",
    "import datetime\n",
    "\n",
    "import kglab\n",
    "import helpers\n",
    "import widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This work-shop will introduce you to downloading and exploring the RDF created in the Sinopia Linked Data Editing environment. We will then build upon these Sinopia data artifacts we created by applying various machine learning technologies and techniques for such tasks as FAST subject heading and template classification. Finally, we will discuss Data Statements and Model Cards and how to apply them to the work\n",
    "we did today.\n",
    "\n",
    "### Workshop Schedule\n",
    "This workshop will be broken down into three parts, with a break between each session.\n",
    "\n",
    "#### 1. Introduction, Setup, Analysis, and Visualization of Sinopia RDF\n",
    "\n",
    "#### 2. Using spaCy and HuggingFace Natural Language Processing (NLP)\n",
    "\n",
    "#### 3. Increasing transparency with Model Cards and Data Statements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up for running Locally or Remotely\n",
    "There are multiple ways to run the [Jupyter notebooks](https://jupyter.org/) in this workshop, the easiest method to load each notebook using the [MyBinder][BINDER] service that will launch a Jupyter lab environment from which you can select and run the notebooks. The most complex method would be download and install Python along with the workshop dependencies on your local laptop or workstation.\n",
    "\n",
    "### Run with MyBinder Cloud Service (the easiest) \n",
    "To run this workshop's Jupyter notebooks on [MyBinder][BINDER]\n",
    "\n",
    "1. Go to the following link https://mybinder.org/v2/gh/jermnelson/ld4-2021-workshop/HEAD \n",
    "1. Launch the container \n",
    "1. When the environment is finished, add `lab` to the end of the URL and you should a similar display to this:\n",
    "   ![MyBinder Jupyter Lab Workshop](images/mybinder-lab-screenshot.png)\n",
    "1. Click on the `01_IntroSetup.ipynb` to launch this notebook. \n",
    "\n",
    "\n",
    "### Local Installation Set-up\n",
    "1. Download and Install latest [Python version](https://python.org/downloads), current version **3.9.6**\n",
    "1. Once Python 3.9.x is installed, launch a terminal window and change to a directory where you want to install the workshop notebooks repository\n",
    "1. Create a Python virtual environment i.e. `python3 -m venv ld4-env`\n",
    "1. Activate the Python virtual environment, \n",
    "   - `source ld4-env/bin/activate` for Macintosh or Linux\n",
    "   - `. ld4-env\\Scripts\\Activate` for Windows\n",
    "1. Clone or copy the workshop repository.\n",
    "   -  If you have [git](https://git-scm.com) installed, run `git clone https://github.com/ld4p/{name-of-repo}`\n",
    "   -  Download and unzip the repository\n",
    "1. Change directories into the Workshop repository and run `pip install -r requirements.txt` to install all of the libraries we will be using for the workshop\n",
    "1. Launch Jupyter lab from the Workshop repository with `jupyter lab`\n",
    "1. Access the running Jupyter lab by accessing the locally running jupyter lab instance at http://localhost:8888 (or another port if 8888 is being used)\n",
    "\n",
    "The data we will be using in for this workship is located at `data/workshop-data.zip`\n",
    "\n",
    "[BINDER]: https://mybinder.org/\n",
    "[COLAB]: https://colab.research.google.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data/workshop-data.zip\n",
      "  inflating: data/5f8c765d-dc4f-45a0-b2d8-87fe29a38712.txt  \n",
      "  inflating: data/65a2b059-5ac1-48a6-adbb-870712c3060c.txt  \n",
      "  inflating: data/ae7a9f2c-a5db-4472-80fe-9a30f311386d.txt  \n",
      "  inflating: data/d900f0f2-d497-4e58-84c5-2099bd31a967.txt  \n",
      "  inflating: data/production.json    \n",
      "  inflating: data/stage-text-nodes.json  \n",
      "  inflating: data/stage.json         \n",
      "  inflating: data/summaries.pkl      \n",
      "  inflating: data/topic_uri_label_utf8.csv  \n"
     ]
    }
   ],
   "source": [
    "! unzip data/workshop-data.zip -d data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief Introduction to Jupyter Notebooks\n",
    "[Jupyter](https://jupyter.org/) notebooks are a popular computing environment in big data and machine learning communities that runs in your web browser. A notebook is made up of one more cells that are contain either documentation, written in [Markdown][MKDOWN], or Python code. You can move cells around, copy, delete, or change the type using the notebook toolbar:\n",
    "\n",
    "![Jupyter Notebook Toolbar](images/jupyter-nb-toolbar.png)\n",
    "\n",
    "Here are the important buttons:\n",
    "\n",
    "#### Saves the notebook to disk\n",
    "![Save Notebook](images/notebook-save.png) \n",
    "  \n",
    "####  Adds a new cell to the notebook\n",
    "![Add cell](images/notebook-add-cell.png)\n",
    "\n",
    "#### Removes current cell (but can paste the cell in a new location)\n",
    "![Cut cell](images/notebook-cut-cell.png) \n",
    "\n",
    "#### Copy current cell\n",
    "  ![Copy cell](images/notebook-copy-cell.png)\n",
    "  \n",
    "#### Paste cell at cursor position\n",
    "![Paste cell](images/notebook-paste-cell.png)\n",
    "\n",
    "#### Runs current cell, either renders Markdown cell to HTML or executes Python code.\n",
    "![Run cell](images/notebook-run-cell.png) \n",
    "\n",
    "#### Stops current running Cell\n",
    "![Stop Running Cell](images/notebook-stop-running-cell.png)\n",
    "\n",
    "#### Dropdown for changing the current cell type\n",
    "![Change cell type dropdown](images/notebook-cell-type-select.png) \n",
    "\n",
    "[MKDOWN]: https://www.markdownguide.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sinopia Group Knowledge Graph\n",
    "We can use [Sinopia API](https://ld4p.github.io/sinopia_api/#tag/resources/paths/~1resource/get) to only retrieve resources associated with a Sinopia group. The general URL pattern is \n",
    "\n",
    "`https://api.{env?}.sinopia.io/resource?group={name}`. \n",
    "\n",
    "Some examples:\n",
    "- Retrieve PCC resources from Sinopia stage environment: `https://api.stage.sinopia.io/resource?group=pcc`\n",
    "- Retrieve Yale resources from Sinopia production: `https://api.sinopia.io/resource?group=yale`\n",
    "\n",
    "To assist in generating the group API URL, we will use the `sinopia_api` widget:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b3d42a257745f7b9b95c5cbeb4afc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(RadioButtons(description='Environment:', options=(('Development', 'https://api.dâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(widgets.sinopia_api_group_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcc_kg = helpers.create_kg(\"https://api.sinopia.io/resource?group=pcc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "478"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving all RDF from Sinopia Stage Environment\n",
    "Using the `sinopia_api` widget to generate the Sinopia API url for all groups, we can then use a helper function, `create_kg` that will download each resource, extract the RDF, and then return the Knowledge Graph after all of the RDF resources have been parsed.\n",
    "\n",
    "**NOTE**: Instead of taking 8+ minutes to run this function, you can just load the existing stage knowledge graph with the following commands:\n",
    "\n",
    "```python\n",
    "stage_kg = kglab.KnowledgeGraph()\n",
    "stage_kg.load_jsonld(\"data/stage.json\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_kg = kglab.KnowledgeGraph()\n",
    "stage_kg.load_jsonld(\"data/stage.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = datetime.datetime.utcnow()\n",
    "print(f\"Started creation of knowledge graph for Sinopia Stage at {start}\")\n",
    "stage_kg = helpers.create_kg(\"https://api.stage.sinopia.io/resource\")\n",
    "end = datetime.datetime.utcnow()\n",
    "print(f\"\"\"Finished at {end}, total time {(end-start).seconds / 60.} minutes\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save the resulting knowledge graph, we will use the method `save_jsonld` that serializes the Sinopia Stage graph to JSON-LD, we will load and use this file in subsequent Jupyter notebooks in this workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_kg.save_jsonld(\"data/stage.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.utcnow()\n",
    "print(f\"Started creation of knowledge graph for Sinopia Production at {start}\")\n",
    "prod_kg = helpers.create_kg(\"https://api.sinopia.io/resource\")\n",
    "end = datetime.datetime.utcnow()\n",
    "print(f\"\"\"Finished at {end}, total time {(end-start).seconds / 60.} minutes\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_kg.save_jsonld(\"data/production.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "Compare the total number of triples for National Library of Medicine in each Sinopia environment; development, stage, and production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
