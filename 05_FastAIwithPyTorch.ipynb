{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e10ea410-9311-4177-8acf-513c4b5e5d74",
   "metadata": {},
   "source": [
    "# FastAI with PyTorch\n",
    "For our final hour, we look at training our own models on Sinopia's RDF for a couple of classification tasks. [FastAI][FASTAI] is a non-profit that provides artificial intellegence training and for our use today, an easy-to-use Python software library that is built upon the [PyTorch](https://pytorch.org/) open-source machine learning framework from Facebook that is widely used in industry and academic research.\n",
    "\n",
    "[FASTAI]: https://www.fast.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5fe1c5-d309-46fa-b172-15bf0e94e104",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%reload_ext lab_black\n",
    "\n",
    "from fastai.tabular.all import *\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import kglab\n",
    "import rdflib\n",
    "import helpers\n",
    "import widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453b61cd-68e1-4a8a-979e-ef949bad3e7d",
   "metadata": {},
   "source": [
    "## Loading Sinopia Stage RDF Text DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd64432d-c1a3-4563-b29d-6f5ed4be542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_kg = kglab.KnowledgeGraph()\n",
    "stage_kg.load_jsonld(\"data/stage.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d11c8b6-7bf0-4f78-9d9a-dffd8a2165c9",
   "metadata": {},
   "source": [
    "## Classifing RDF resource by their Template\n",
    "In Sinopia, each resource uses at least one resource template for constructing the Sinopia's user interface. Currently, when a user imports RDF into the editor, either through the Questioning Authority search or through the **Load RDF** tab, the user is prompted to selected the template to use and Sinopia does its best to matche the template's properties to the incoming RDF.\n",
    "\n",
    "This classification task extends the initial work done in last year's LD4 presentation, \n",
    "[A Machine Learning Approach for Classifying Sinopia's RDF](https://ld4p.github.io/classify-rdf-2020/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e002c9-9a4a-41a2-b800-2dc88632698a",
   "metadata": {},
   "source": [
    "### Step One - Generate Pandas Dataframe\n",
    "We will run a SPARQL query on our stage knowledge graph, iterate through the results to generate a list of dictionaries from the `helpers.predicate_row`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dc185a-720b-4f6e-aa3e-4eaa3163b97f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for row in stage_kg.query(\n",
    "    \"\"\"\n",
    "SELECT ?template ?url \n",
    "WHERE {\n",
    "   ?url <http://sinopia.io/vocabulary/hasResourceTemplate> ?template .\n",
    "   FILTER isIRI(?url)\n",
    "} \"\"\"\n",
    "):\n",
    "    # Skip if RDF resource is a Sinopia resource template\n",
    "    if str(row[0]).startswith(\"sinopia:template:resource\"):\n",
    "        continue\n",
    "    data.append(helpers.predicate_row(row[1], stage_kg.rdf_graph()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a0b312-cd3e-459d-8743-550bef7591ea",
   "metadata": {},
   "source": [
    "For the list of dictionaries that have the predicate frequencies, create a Pandas DataFramek and then replace missing values with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c881460f-d97c-4dbe-a7a6-52fa437764bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_df = pd.DataFrame(data)\n",
    "stage_df = stage_df.fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30ccd59-0845-4453-902e-5d50d6b827ac",
   "metadata": {},
   "source": [
    "Shape and information about the `stage_df` DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffc888f-b9f2-4d03-8fad-6f746da3c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stage_df.shape)\n",
    "print(stage_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ac4c89-f284-46a9-aa57-39004e108088",
   "metadata": {},
   "source": [
    "Generate a random sample of 10 to see examples of individual Series in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c8160c-a2d5-4245-bdad-986384a32d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c969a3e-4619-4c49-8ee8-0e946c6a3489",
   "metadata": {},
   "source": [
    "### Step Two - Split, Preprocess, and Load Data\n",
    "First we will create a copy of `stage_df` DataFrame, with the `uri` column as we don't want to train our model on this identifier. Later if we need, we can lookup the `uri` in the original `stage_df` dataframe to retrieve the URI. We will also remove the `sinopia:hasResourceTemplate` column because it doesn't add any information. We will then make sure that we don't have rows that have unique templates (as this will impact later training).\n",
    "\n",
    "Next we split our data into training and validation sets with our validation set contain 20% of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa8939f-0a9b-425b-b795-26affa3db43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_df_copy = stage_df.drop(\n",
    "    columns=[\"uri\", \"http://sinopia.io/vocabulary/hasResourceTemplate\"]\n",
    ")\n",
    "stage_df_clean = stage_df_copy[\n",
    "    stage_df_copy.duplicated(subset=[\"template\"], keep=False)\n",
    "]\n",
    "splits = helpers.create_splits(stage_df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0cafbb-945e-4573-bf28-3301dcbdd061",
   "metadata": {},
   "source": [
    "Using the FastAI's TabularPandas class, we will pass in some parameters to preprocess the `stage_df_copy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422b2708-e01e-4119-9463-000a1ef58725",
   "metadata": {},
   "outputs": [],
   "source": [
    "continous = [col for col in stage_df_clean.columns]\n",
    "continous.pop(0)  # Removes template from our continous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9932e46-c01c-43a5-86e9-a99d69eb8f1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stage_to = TabularPandas(\n",
    "    stage_df_clean,\n",
    "    procs=[Categorify],\n",
    "    cont_names=continous,\n",
    "    y_names=\"template\",\n",
    "    y_block=CategoryBlock,\n",
    "    splits=splits,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7986d656-b5d7-42e5-8083-bbe215d3b542",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_to.xs.iloc[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8356ab4-5ef1-4941-a597-e1ff96387599",
   "metadata": {},
   "source": [
    "Finally, we will create a FastAI `DataLoader` that we can pass to the `leaner` object for training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00b1017-5d7c-4f1a-81e6-39d838ad82c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_data_loader = stage_to.dataloaders(bs=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a37824-6a9b-4eae-8217-fe8f92217843",
   "metadata": {},
   "source": [
    "The `TabularDataLoader` provides a method batching up our data in groups of 64 (set when we passed in the `bs` parameter above) and we see an example of a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a5c897-0a60-4bbd-a373-2b8075153c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_data_loader.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada413ee-2618-480a-b824-0fdaa2be8324",
   "metadata": {},
   "source": [
    "### Step Three - Create Learner and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70f222e-5655-42eb-96e0-d1bc96090710",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_learner = tabular_learner(stage_data_loader, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73d9f31-b2cc-4543-91cd-ec881b1747fd",
   "metadata": {},
   "source": [
    "With the `stage_learner` object, we can graphically estimate the learning rate that will be used in training our new model. We can examine the model by printing it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db57b7e-c6dd-48fd-9d2a-a87e2f97a3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_learner.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1c93ad-03c5-406f-98a2-1af18be83867",
   "metadata": {},
   "source": [
    "In our `TabularModel` neural net we have three layers, with the first input layer does the following:\n",
    "  1.  Applies a PyTorch [Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) to the incoming data\n",
    "  1.  Applies the PyTorch [ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html) activation\n",
    "  1.  Applies a [batch normalization](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html) on our batch of 65\n",
    "  \n",
    "The second hiddent layer of does similar processing as our first layer and the layer third produces the final resultes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88930ba-3df9-41fa-8966-d1f2cd115d71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stage_learner.lr_find()\n",
    "stage_learner.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f87eda6-c035-4d89-becc-2af5c4e52fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_learner.fit_one_cycle(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a1f62f-df42-42ff-b965-6dd9a66c0eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_learner.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80bffbc-6ec6-49f0-971c-c471710ae0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "row, class_, probs = stage_learner.predict(stage_df_copy.iloc[23])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42f3dfa-75b2-4cf4-860b-8659a97a8838",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "So far we have been using all of the RDF in Sinopia's stage environment, repeat the steps above for Sinopia production environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c286ac8-3124-42d4-97ad-41ba49474304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacb0d30-c5d3-4ac1-844a-2d134ac82f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
